 
import oci

# Setup basic variables
# Auth Config
# TODO: Please update config profile name and use the compartmentId that has policies grant permissions for using Generative AI Service
compartment_id = "ocid1.compartment.oc1..aaaaaaaau5q457a7teqkjce4oenoiz6bmc4g3s74a5543iqbm7xwplho44fq"
CONFIG_PROFILE = "DEFAULT"
config = oci.config.from_file('~/.oci/config', CONFIG_PROFILE)

# Service endpoint
endpoint = "https://inference.generativeai.us-chicago-1.oci.oraclecloud.com"

generative_ai_inference_client = oci.generative_ai_inference.GenerativeAiInferenceClient(config=config, service_endpoint=endpoint, retry_strategy=oci.retry.NoneRetryStrategy(), timeout=(10,240))
chat_detail = oci.generative_ai_inference.models.ChatDetails()

content = oci.generative_ai_inference.models.TextContent()
content.text = """
hi, who r u
"""
message = oci.generative_ai_inference.models.Message()
message.role = "USER"
message.content = [content]

chat_request = oci.generative_ai_inference.models.GenericChatRequest()
chat_request.api_format = oci.generative_ai_inference.models.BaseChatRequest.API_FORMAT_GENERIC
chat_request.messages = [message]
chat_request.max_tokens = 600
chat_request.temperature = 1
chat_request.top_p = 1


chat_detail.serving_mode = oci.generative_ai_inference.models.OnDemandServingMode(model_id="xai.grok-4")
chat_detail.chat_request = chat_request
chat_detail.compartment_id = compartment_id

#### open stream mode
chat_request.is_stream=True

chat_response = generative_ai_inference_client.chat(chat_detail)


import json


for event in chat_response.data.events():
  output =  json.loads(event.data)
  if output.get('message') is not None:
      import time
      time.sleep(1)
      print(output['message']['content'][0]['text'],end='',flush=True)

 
